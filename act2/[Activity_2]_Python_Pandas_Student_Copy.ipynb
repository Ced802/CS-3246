{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrxbKKJZtPzj"
   },
   "source": [
    "# **Activity 2: Python-Pandas Exercise**\n",
    "\n",
    "Objectives:\n",
    "- Understand Python syntax (variables, loops, functions).\n",
    "- Learn Pandas basics (Series, DataFrames, reading files).\n",
    "- Perform data cleaning (handling missing values, correcting formats, removing duplicates).\n",
    "- Apply concepts in a real-world case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNQbxlCPtvXZ"
   },
   "source": [
    "# Part 1: Hands-on Python & Pandas Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH2WqeaY38NC"
   },
   "source": [
    "1. Install the Pandas library in your environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GPhWF_2u5Qxy",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:51.484035Z",
     "start_time": "2025-02-14T09:19:50.227518Z"
    }
   },
   "source": [
    "pip install pandas"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\johnf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\johnf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZC17Lf1zT3Q"
   },
   "source": [
    "2. Import the  pandas package under the name `pd`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lR6fv9XE3Pw3",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:53.646311Z",
     "start_time": "2025-02-14T09:19:51.520932Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO_MlGtx3Wj5"
   },
   "source": [
    "3. Print the pandas version"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y4lcL4Nb3SrJ",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:53.677709Z",
     "start_time": "2025-02-14T09:19:53.663262Z"
    }
   },
   "source": [
    "print(pd.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWJFiRZ03pwH"
   },
   "source": [
    "4. Create a variable `x` with the value 10 and a string variable `y` with \"Fortes in Fide!\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QCkALKg_3vig",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:53.708608Z",
     "start_time": "2025-02-14T09:19:53.694622Z"
    }
   },
   "source": [
    "x = 10\n",
    "y = \"Fortes in Fide!\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBzRK3sY5Wfh"
   },
   "source": [
    "5. Define a list with numbers `[1, 2, 3, 4, 5]` and a dictionary with keys `name` and `age`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8Zg7dgz5XPA",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:53.739635Z",
     "start_time": "2025-02-14T09:19:53.724678Z"
    }
   },
   "source": [
    "list1 = [1,2,3,4,5]\n",
    "name = {\n",
    "    \"name\": \"age\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbsHcq7w5hE2"
   },
   "source": [
    "6. Write a function `greet(name)` that returns \"Magis, (name)\"!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LHKMev_a5mJX",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:53.769554Z",
     "start_time": "2025-02-14T09:19:53.755623Z"
    }
   },
   "source": [
    "\n",
    "def greet(name):\n",
    "    print(f\"Magis, {name}\")\n",
    "userName=\"glenn\"\n",
    "greet(userName)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magis, glenn\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_UBbRZKYBFF"
   },
   "source": [
    "7. Write a Python function that takes a user‚Äôs name as input and prints a personalized greeting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:57.341455Z",
     "start_time": "2025-02-14T09:19:53.785525Z"
    }
   },
   "source": [
    "def greeting(name):\n",
    "    print(f\"Hello Welcome Back {name}!\")\n",
    "\n",
    "userName = input(\"Enter your name: \")\n",
    "greeting(userName)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome Back glenn!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GEjHQ-PYRj2"
   },
   "source": [
    "8. Modify **Number 7** that if the user does not enter a name, it defaults to \"Guest\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rYfMyyQeYbf6",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:20:08.419900Z",
     "start_time": "2025-02-14T09:20:07.394367Z"
    }
   },
   "source": [
    "def greeting(name):\n",
    "    print(f\"Hello Welcome Back {name}!\")\n",
    "\n",
    "userName = input(\"Enter your name: \")\n",
    "\n",
    "if not userName:\n",
    "    userName = \"Guest\"\n",
    "\n",
    "greeting(userName)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome Back Guest!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG-Ubf3259sb"
   },
   "source": [
    "9. Create a Pandas Series from `[10, 20, 30, 40]`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oGThKfqQ5-sj",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.679940Z",
     "start_time": "2025-02-14T09:19:59.665972Z"
    }
   },
   "source": [
    "newSeries = pd.Series([10,20,30,40])\n",
    "print(newSeries)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeSr_ozS6Wc5"
   },
   "source": [
    "10.  Create a DataFrame with columns `A` and `B`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ytbYen7w6Mmv",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.725662Z",
     "start_time": "2025-02-14T09:19:59.695894Z"
    }
   },
   "source": [
    "newDf = pd.DataFrame({\n",
    "    \"A\":[1,2,3],\n",
    "    \"B\":[1,2,3]\n",
    "})\n",
    "print(newDf)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  1\n",
      "1  2  2\n",
      "2  3  3\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mAive8s7kfU"
   },
   "source": [
    "# Part 2: Working with a Dataset üõ•Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6daMs_F8SPx"
   },
   "source": [
    "1. Load the Titanic dataset from a local file and display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zi-ufFmj9e4h",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.755688Z",
     "start_time": "2025-02-14T09:19:59.741648Z"
    }
   },
   "source": [
    "titanicData = pd.read_csv(\"titanic_dataset.csv\")\n",
    "print(titanicData.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "405AKURC9sqB"
   },
   "source": [
    "2. Display the dataset's column names, data types."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "88-8AT8W9uaI",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.786979Z",
     "start_time": "2025-02-14T09:19:59.773084Z"
    }
   },
   "source": [
    "print(titanicData.info())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh9FsKUx9-8S"
   },
   "source": [
    "3. Display the dataset's missing values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "olw7wFVH9-rG",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:21:11.098938Z",
     "start_time": "2025-02-14T09:21:11.088963Z"
    }
   },
   "source": [
    "missing_values = titanicData.isnull().sum()\n",
    "print(missing_values)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNAGBAXv-LXs"
   },
   "source": [
    "4. Display the `Name`, `Age`, and `Fare` columns from the dataset. (first 10)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LNRu6hI7-dUV",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.862793Z",
     "start_time": "2025-02-14T09:19:59.853822Z"
    }
   },
   "source": [
    "print(titanicData[[\"Name\", \"Age\", \"Fare\"]].head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Name   Age     Fare\n",
      "0                              Kelly, Mr. James  34.5   7.8292\n",
      "1              Wilkes, Mrs. James (Ellen Needs)  47.0   7.0000\n",
      "2                     Myles, Mr. Thomas Francis  62.0   9.6875\n",
      "3                              Wirz, Mr. Albert  27.0   8.6625\n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0  12.2875\n",
      "5                    Svensson, Mr. Johan Cervin  14.0   9.2250\n",
      "6                          Connolly, Miss. Kate  30.0   7.6292\n",
      "7                  Caldwell, Mr. Albert Francis  26.0  29.0000\n",
      "8     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  18.0   7.2292\n",
      "9                       Davies, Mr. John Samuel  21.0  24.1500\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2iFTTa2-nAv"
   },
   "source": [
    " 5. Print the descriptive statistics of the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VvurbDoL-xJE",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.908672Z",
     "start_time": "2025-02-14T09:19:59.890720Z"
    }
   },
   "source": [
    "print(titanicData.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
      "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
      "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
      "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
      "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
      "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
      "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
      "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  418.000000  417.000000  \n",
      "mean     0.392344   35.627188  \n",
      "std      0.981429   55.907576  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.895800  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.500000  \n",
      "max      9.000000  512.329200  \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U95dijMI-9x1"
   },
   "source": [
    "6. Remove rows with missing values in the `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mMKNND-E_jnL",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:37.628864Z",
     "start_time": "2025-02-14T09:22:37.619888Z"
    }
   },
   "source": [
    "newTitanicData = titanicData[\"Age\"].dropna()\n",
    "dataCount = newTitanicData.count()\n",
    "print(titanicData.count())\n",
    "print(dataCount)\n",
    "# 418 (rows) - 86 (null age values) = 332"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    418\n",
      "Survived       418\n",
      "Pclass         418\n",
      "Name           418\n",
      "Sex            418\n",
      "Age            332\n",
      "SibSp          418\n",
      "Parch          418\n",
      "Ticket         418\n",
      "Fare           417\n",
      "Cabin           91\n",
      "Embarked       418\n",
      "dtype: int64\n",
      "332\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-2X_e-fFHI5"
   },
   "source": [
    "7. Remove duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l2X-ym9eFIT-",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:19:59.972040Z",
     "start_time": "2025-02-14T09:19:59.957620Z"
    }
   },
   "source": "print(titanicData.drop_duplicates())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0            892         0       3   \n",
      "1            893         1       3   \n",
      "2            894         0       2   \n",
      "3            895         0       3   \n",
      "4            896         1       3   \n",
      "..           ...       ...     ...   \n",
      "413         1305         0       3   \n",
      "414         1306         1       1   \n",
      "415         1307         0       3   \n",
      "416         1308         0       3   \n",
      "417         1309         0       3   \n",
      "\n",
      "                                             Name     Sex   Age  SibSp  Parch  \\\n",
      "0                                Kelly, Mr. James    male  34.5      0      0   \n",
      "1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                       Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                                Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "..                                            ...     ...   ...    ...    ...   \n",
      "413                            Spector, Mr. Woolf    male   NaN      0      0   \n",
      "414                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n",
      "415                  Saether, Mr. Simon Sivertsen    male  38.5      0      0   \n",
      "416                           Ware, Mr. Frederick    male   NaN      0      0   \n",
      "417                      Peter, Master. Michael J    male   NaN      1      1   \n",
      "\n",
      "                 Ticket      Fare Cabin Embarked  \n",
      "0                330911    7.8292   NaN        Q  \n",
      "1                363272    7.0000   NaN        S  \n",
      "2                240276    9.6875   NaN        Q  \n",
      "3                315154    8.6625   NaN        S  \n",
      "4               3101298   12.2875   NaN        S  \n",
      "..                  ...       ...   ...      ...  \n",
      "413           A.5. 3236    8.0500   NaN        S  \n",
      "414            PC 17758  108.9000  C105        C  \n",
      "415  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
      "416              359309    8.0500   NaN        S  \n",
      "417                2668   22.3583   NaN        C  \n",
      "\n",
      "[418 rows x 12 columns]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-SvrKnKFL1m"
   },
   "source": [
    "8. Compute and display the correlation matrix of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:45.107350Z",
     "start_time": "2025-02-14T09:22:45.062471Z"
    }
   },
   "source": [
    "print(titanicData.corr())"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Kelly, Mr. James'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtitanicData\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:11049\u001B[0m, in \u001B[0;36mDataFrame.corr\u001B[1;34m(self, method, min_periods, numeric_only)\u001B[0m\n\u001B[0;32m  11047\u001B[0m cols \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m  11048\u001B[0m idx \u001B[38;5;241m=\u001B[39m cols\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m> 11049\u001B[0m mat \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m  11051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m  11052\u001B[0m     correl \u001B[38;5;241m=\u001B[39m libalgos\u001B[38;5;241m.\u001B[39mnancorr(mat, minp\u001B[38;5;241m=\u001B[39mmin_periods)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:1993\u001B[0m, in \u001B[0;36mDataFrame.to_numpy\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1991\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1992\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(dtype)\n\u001B[1;32m-> 1993\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype:\n\u001B[0;32m   1995\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(result, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001B[0m, in \u001B[0;36mBlockManager.as_array\u001B[1;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[0;32m   1692\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1694\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interleave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1695\u001B[0m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[0;32m   1696\u001B[0m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001B[0m, in \u001B[0;36mBlockManager._interleave\u001B[1;34m(self, dtype, na_value)\u001B[0m\n\u001B[0;32m   1751\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1752\u001B[0m         arr \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mget_values(dtype)\n\u001B[1;32m-> 1753\u001B[0m     \u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindexer\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m arr\n\u001B[0;32m   1754\u001B[0m     itemmask[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m itemmask\u001B[38;5;241m.\u001B[39mall():\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Kelly, Mr. James'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v_OG5PPLUcL"
   },
   "source": [
    "# Part 2: Working with Case Studies\n",
    "\n",
    "When working on these case studies, **always ensure that your code is properly documented and clearly presented**. Follow these key principles:  \n",
    "\n",
    "### **1. Always Show Your Code**  \n",
    "- Every step of data exploration, cleaning, and analysis should include **visible code outputs**.  \n",
    "- Do not skip showing your process, as transparency is essential for reproducibility.  \n",
    "\n",
    "### **2. Proper Documentation is Necessary**  \n",
    "- Use **comments (`#`) in Python** to explain your code clearly.  \n",
    "- Add **Markdown cells** to describe each step before executing the code.  \n",
    "- Explain key findings in simple language to make the analysis easy to understand.  \n",
    "\n",
    "### **3. Use Readable and Organized Code**  \n",
    "- Follow a **step-by-step approach** to keep the notebook structured.  \n",
    "- Use **proper variable names** and avoid hardcoding values where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOzxo0NoFZJ5"
   },
   "source": [
    "# **Case Study 1: Iris Flower Classification** üå∏  \n",
    "\n",
    "### **Background**  \n",
    "A botanical research institute wants to develop an automated system that classifies different species of **iris flowers** based on their **sepal and petal measurements**.  The dataset consists of **150 samples**, labeled as **Setosa, Versicolor, or Virginica**.  \n",
    "\n",
    "### **Problem Statement**  \n",
    "Can we use **sepal and petal dimensions** to correctly classify the **species of an iris flower**?  \n",
    "\n",
    "### **Task Description**  \n",
    "\n",
    "#### **1. Data Exploration**  \n",
    "- Load the dataset and display the first few rows.  \n",
    "- Identify any missing or inconsistent values.  \n",
    "\n",
    "#### **2. Data Cleaning**  \n",
    "- Check for missing values and handle them appropriately.  \n",
    "- Convert categorical species labels into a format suitable for analysis.  \n",
    "\n",
    "#### **3. Basic Data Analysis**  \n",
    "- Find the average sepal and petal dimensions for each species.  \n",
    "- Identify correlations between different flower measurements.  \n",
    "\n",
    "#### **4. Visualization**  \n",
    "- Create simple visualizations (e.g., histograms, scatter plots) to understand data distribution.  \n",
    "\n",
    "#### **5. Insights & Interpretation**  \n",
    "- Summarize key findings, such as which features best distinguish flower species.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Exploration*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VpnqIg63LiAH",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:48.135508Z",
     "start_time": "2025-02-14T09:22:48.120550Z"
    }
   },
   "source": [
    "irisDataset = pd.read_csv(\"iris_dataset.csv\") #Load in CSV file\n",
    "print(irisDataset.head()) #Return first 5 \n",
    "print(irisDataset.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:50.614510Z",
     "start_time": "2025-02-14T09:22:50.599550Z"
    }
   },
   "source": [
    "#Show Data types for each column values and check for null or missing values\n",
    "print(irisDataset.info())\n",
    "print(\"\\n\")\n",
    "\n",
    "missing_values = irisDataset.isnull().sum() #Confirmation that there is no null values\n",
    "print(missing_values)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "\n",
      "\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acBPPZF1LN1S"
   },
   "source": [
    "# **Case Study 2: Netflix Content Analysis** üé¨  \n",
    "\n",
    "## **Background**  \n",
    "Netflix is a leading streaming platform with a vast collection of movies and TV shows. The company wants to analyze its **content library** to understand trends in **genres, release years, and regional distribution**.  \n",
    "\n",
    "## **Problem Statement**  \n",
    "How can we use **Netflix‚Äôs dataset** to gain insights into content distribution, popular genres, and release trends over time?  \n",
    "\n",
    "## **Task Description**  \n",
    "\n",
    "### **1. Data Exploration**  \n",
    "- Load the dataset and inspect its structure.  \n",
    "- Identify key columns such as title, genre, release year, and country.  \n",
    "\n",
    "### **2. Data Cleaning**  \n",
    "- Check for missing or incorrect values in key columns.  \n",
    "- Remove duplicates and format the date-related data properly.  \n",
    "\n",
    "### **3. Basic Data Analysis**  \n",
    "- Count the number of movies vs. TV shows.  \n",
    "- Identify the most common genres and countries producing content.  \n",
    "- Analyze the number of releases per year to observe trends.  \n",
    "\n",
    "### **4. Insights & Interpretation**  \n",
    "- Summarize key findings, such as trends in Netflix's content production over time.  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vrd7hTehLigX",
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:55.661300Z",
     "start_time": "2025-02-14T09:22:55.602447Z"
    }
   },
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "netflixData = pd.read_csv('netflix_dataset.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(netflixData.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  show_id     type                  title         director  \\\n",
      "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
      "1      s2  TV Show          Blood & Water              NaN   \n",
      "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
      "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
      "4      s5  TV Show           Kota Factory              NaN   \n",
      "\n",
      "                                                cast        country  \\\n",
      "0                                                NaN  United States   \n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
      "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
      "3                                                NaN            NaN   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "0  September 25, 2021          2020  PG-13     90 min   \n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "2  September 24, 2021          2021  TV-MA   1 Season   \n",
      "3  September 24, 2021          2021  TV-MA   1 Season   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "\n",
      "                                           listed_in  \\\n",
      "0                                      Documentaries   \n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "2  Crime TV Shows, International TV Shows, TV Act...   \n",
      "3                             Docuseries, Reality TV   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "\n",
      "                                         description  \n",
      "0  As her father nears the end of his life, filmm...  \n",
      "1  After crossing paths at a party, a Cape Town t...  \n",
      "2  To protect his family from a powerful drug lor...  \n",
      "3  Feuds, flirtations and toilet talk go down amo...  \n",
      "4  In a city of coaching centers known to train I...  \n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:57.231343Z",
     "start_time": "2025-02-14T09:22:57.219342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the information(key columns) about the DataFrame\n",
    "print(netflixData[[\"title\", \"listed_in\", \"release_year\", \"country\"]].info())\n",
    "\n",
    "# The title, genres, and release year columns do not have any missing values"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         8807 non-null   object\n",
      " 1   listed_in     8807 non-null   object\n",
      " 2   release_year  8807 non-null   int64 \n",
      " 3   country       7976 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 275.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:58.236311Z",
     "start_time": "2025-02-14T09:22:58.224338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking for missing or incorrect values\n",
    "print(netflixData[[\"title\", \"listed_in\", \"release_year\", \"country\"]].isnull().sum())\n",
    "\n",
    "# There are 831 missing values in the country column"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title             0\n",
      "listed_in         0\n",
      "release_year      0\n",
      "country         831\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:22:59.343410Z",
     "start_time": "2025-02-14T09:22:59.328447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This code will remove duplicates from the DataFrame\n",
    "rows_before = netflixData.shape[0]\n",
    "netflixData_cleaned = netflixData.drop_duplicates()\n",
    "rows_after = netflixData_cleaned.shape[0]\n",
    "\n",
    "print(f\"Rows before dropping duplicates: {rows_before}\")\n",
    "print(f\"Rows after dropping duplicates: {rows_after}\")\n",
    "\n",
    "# This shows that there are no duplicates in the DataFrame"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping duplicates: 8807\n",
      "Rows after dropping duplicates: 8807\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T09:23:00.548482Z",
     "start_time": "2025-02-14T09:23:00.448467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This will format the date_added column into DateTime format\n",
    "\n",
    "netflixData_cleaned['date_added'] = pd.to_datetime(netflixData_cleaned['date_added'])\n",
    "print(netflixData_cleaned.info(), \"\\n\")\n",
    "print(netflixData_cleaned)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \" August 4, 2017\" doesn't match format \"%B %d, %Y\", at position 1442. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# This will format the date_added column into DateTime format\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m netflixData_cleaned[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_added\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetflixData_cleaned\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate_added\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(netflixData_cleaned\u001B[38;5;241m.\u001B[39minfo(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(netflixData_cleaned)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1061\u001B[0m             result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39mtz_localize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutc\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, ABCSeries):\n\u001B[1;32m-> 1063\u001B[0m     cache_array \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_listlike\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cache_array\u001B[38;5;241m.\u001B[39mempty:\n\u001B[0;32m   1065\u001B[0m         result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39mmap(cache_array)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001B[0m, in \u001B[0;36m_maybe_cache\u001B[1;34m(arg, format, cache, convert_listlike)\u001B[0m\n\u001B[0;32m    245\u001B[0m unique_dates \u001B[38;5;241m=\u001B[39m unique(arg)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(unique_dates) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(arg):\n\u001B[1;32m--> 247\u001B[0m     cache_dates \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43munique_dates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;66;03m# GH#45319\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmixed\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_array_strptime_with_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mutc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m result, tz_parsed \u001B[38;5;241m=\u001B[39m objects_to_datetime64(\n\u001B[0;32m    436\u001B[0m     arg,\n\u001B[0;32m    437\u001B[0m     dayfirst\u001B[38;5;241m=\u001B[39mdayfirst,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    441\u001B[0m     allow_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    442\u001B[0m )\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tz_parsed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001B[39;00m\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;66;03m# is in UTC\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001B[0m, in \u001B[0;36m_array_strptime_with_fallback\u001B[1;34m(arg, name, utc, fmt, exact, errors)\u001B[0m\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_array_strptime_with_fallback\u001B[39m(\n\u001B[0;32m    457\u001B[0m     arg,\n\u001B[0;32m    458\u001B[0m     name,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    462\u001B[0m     errors: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m    463\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Index:\n\u001B[0;32m    464\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 467\u001B[0m     result, tz_out \u001B[38;5;241m=\u001B[39m \u001B[43marray_strptime\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfmt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mutc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mutc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tz_out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    469\u001B[0m         unit \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdatetime_data(result\u001B[38;5;241m.\u001B[39mdtype)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mstrptime.pyx:501\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.strptime.array_strptime\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mstrptime.pyx:451\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.strptime.array_strptime\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mstrptime.pyx:583\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: time data \" August 4, 2017\" doesn't match format \"%B %d, %Y\", at position 1442. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
